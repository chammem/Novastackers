# -*- coding: utf-8 -*-
"""recommandation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VnjxYX04harE8S8fctVfgADl2u4oDDpZ
"""


import kagglehub
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from joblib import dump
from scipy.sparse import coo_matrix
import os
from pathlib import Path
from fastapi import FastAPI
from joblib import load
from pydantic import BaseModel
from pymongo import MongoClient

app = FastAPI()

# Configuration de la base de données MongoDB
MONGO_URI = os.getenv("MONGODB_URI", "mongodb+srv://mohammedazizgawet:novastackers@sustainafood.ihxbt.mongodb.net/SustainaFood?retryWrites=true&w=majority&appName=SustainaFood")
DB_NAME = "SustainaFood"
client = MongoClient(MONGO_URI)
db = client[DB_NAME]

# Charger les utilisateurs et produits depuis MongoDB
def load_users_and_products():
    users = list(db.users.find({}, {"_id": 1}))
    products = list(db.products.find({}, {"_id": 1}))
    return users, products

# Charger les interactions utilisateur-produit depuis MongoDB
def load_interactions():
    interactions = list(db.interactions.find({}, {"user_id": 1, "product_id": 1, "count": 1}))
    return interactions

# Préparer la matrice utilisateur-produit
def prepare_matrix_from_db():
    users, products = load_users_and_products()
    interactions = load_interactions()

    # Créer des mappings user_id et product_id
    user_map = {str(user["_id"]): i for i, user in enumerate(users)}
    product_map = {str(product["_id"]): i for i, product in enumerate(products)}

    # Construire la matrice sparse
    rows = [user_map[str(interaction["user_id"])] for interaction in interactions]
    cols = [product_map[str(interaction["product_id"])] for interaction in interactions]
    counts = [interaction["count"] for interaction in interactions]

    matrix = coo_matrix((counts, (rows, cols)), shape=(len(users), len(products)))
    return user_map, product_map, matrix.tocsr()

# Mettre à jour les recommandations
def update_recommendations():
    user_map, product_map, matrix = prepare_matrix_from_db()
    model = train_model(matrix)
    save_model(model, user_map, product_map)
    print("Recommandations mises à jour avec succès !")

@app.post("/update-recommendations")
def update_recommendations_endpoint():
    try:
        update_recommendations()
        return {"success": True, "message": "Recommandations mises à jour avec succès !"}
    except Exception as e:
        return {"success": False, "message": str(e)}

# Charger les artefacts
artifacts_path = os.path.join(os.path.dirname(__file__), "model/recommendation_artifacts.joblib")
artifacts = load(artifacts_path)
model = artifacts['model']
user_map = artifacts['user_map']
product_map = artifacts['product_map']

class RecommendationRequest(BaseModel):
    user_id: int

@app.post("/recommendations")
def get_recommendations(request: RecommendationRequest):
    user_id = request.user_id
    if user_id not in user_map:
        return {"success": False, "message": "Utilisateur non trouvé"}
    
    user_index = user_map[user_id]
    distances, indices = model.kneighbors([user_index])
    recommended_products = [
        {"product_id": list(product_map.keys())[i], "similarity": distances[0][j]}
        for j, i in enumerate(indices[0])
    ]
    
    return {"success": True, "recommendations": recommended_products}

def download_dataset():
    """Télécharge le dataset depuis Kaggle Hub"""
    print("Téléchargement du dataset depuis Kaggle Hub...")
    try:
        path = kagglehub.dataset_download("psparks/instacart-market-basket-analysis")
        print(f"Dataset téléchargé à: {path}")
        return path
    except Exception as e:
        print(f"Erreur lors du téléchargement: {e}")
        raise

def load_data(dataset_path):
    """Charge les données depuis les fichiers CSV"""
    print("Chargement des données...")
    try:
        orders = pd.read_csv(os.path.join(dataset_path, 'orders.csv'))
        order_products = pd.read_csv(os.path.join(dataset_path, 'order_products__prior.csv'))
        products = pd.read_csv(os.path.join(dataset_path, 'products.csv'))

        # Fusion des données
        merged = order_products.merge(orders, on='order_id').merge(products, on='product_id')
        return merged
    except Exception as e:
        print(f"Erreur lors du chargement des données: {e}")
        raise

def prepare_matrix(data, sample_fraction=0.1):
    """Version optimisée pour la création et affichage de la matrice"""
    print("\nPréparation de la matrice optimisée...")

    try:
        # Échantillonnage pour le développement
        if sample_fraction < 1.0:
            unique_users = data['user_id'].unique()
            sample_users = np.random.choice(unique_users,
                                         size=int(len(unique_users)*sample_fraction),
                                         replace=False)
            data = data[data['user_id'].isin(sample_users)]
            print(f"Échantillon: {len(sample_users)} utilisateurs")

        # Création d'un mapping des IDs
        user_ids = data['user_id'].unique()
        product_ids = data['product_id'].unique()

        user_map = {u: i for i, u in enumerate(user_ids)}
        product_map = {p: i for i, p in enumerate(product_ids)}

        # Comptage des interactions
        grouped = data.groupby(['user_id', 'product_id']).size().reset_index(name='count')

        # Création de la matrice sparse COO
        rows = grouped['user_id'].map(user_map)
        cols = grouped['product_id'].map(product_map)
        counts = grouped['count']

        matrix = coo_matrix((counts, (rows, cols)),
                          shape=(len(user_ids), len(product_ids)))

        # Conversion en CSR pour l'efficacité
        matrix_csr = matrix.tocsr()

        # Affichage de la matrice
        print("\nAperçu de la matrice sparse:")
        print(f"Format: {matrix_csr.shape[0]} utilisateurs x {matrix_csr.shape[1]} produits")
        print(f"Nombre total d'interactions: {matrix_csr.nnz}")

        # Afficher une sous-matrice pour visualisation
        print("\nExtrait de la matrice (10x10 premiers éléments):")
        dense_sample = matrix_csr[:10, :10].toarray()
        print(pd.DataFrame(dense_sample,
                         index=[f"User_{i}" for i in range(10)],
                         columns=[f"Prod_{i}" for i in range(10)]))

        return user_map, product_map, matrix_csr, grouped

    except Exception as e:
        print(f"Erreur lors de la préparation de la matrice: {e}")
        raise

def train_model(matrix_csr):
    """Entraîne le modèle de recommandation"""
    print("\nEntraînement du modèle...")
    try:
        model = NearestNeighbors(metric='cosine',
                               algorithm='brute',
                               n_neighbors=5)  # Réduit pour l'exemple
        model.fit(matrix_csr)
        print("Modèle entraîné avec succès!")
        return model
    except Exception as e:
        print(f"Erreur lors de l'entraînement: {e}")
        raise

def save_model(model, user_map, product_map):
    """Sauvegarde des artefacts du modèle"""
    print("\nSauvegarde des artefacts...")
    try:
        os.makedirs('model', exist_ok=True)
        dump({
            'model': model,
            'user_map': user_map,
            'product_map': product_map
        }, 'model/recommendation_artifacts.joblib')
        print("Artefacts sauvegardés dans model/recommendation_artifacts.joblib")
    except Exception as e:
        print(f"Erreur lors de la sauvegarde: {e}")
        raise

def main():
    try:
        # Téléchargement
        dataset_path = download_dataset()

        # Chargement
        data = load_data(dataset_path)
        print(f"\nDonnées chargées: {len(data)} lignes")

        # Préparation avec affichage
        user_map, product_map, matrix, grouped = prepare_matrix(data, sample_fraction=0.1)

        # Entraînement
        model = train_model(matrix)

        # Sauvegarde
        save_model(model, user_map, product_map)

        # Exemple de recommandation
        print("\nExemple de recommandation:")
        sample_user_id = grouped.iloc[0]['user_id']
        user_index = user_map[sample_user_id]
        distances, indices = model.kneighbors(matrix[user_index])

        print(f"Recommandations pour l'utilisateur {sample_user_id}:")
        for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
            product_id = list(product_map.keys())[list(product_map.values()).index(idx)]
            print(f"{i+1}. Produit {product_id} (similarité: {1-dist:.2f})")

        print("\nProcessus terminé avec succès!")
    except Exception as e:
        print(f"\nÉchec: {e}")

if __name__ == "__main__":
    # kagglehub.login()  # Décommentez si nécessaire
    main()